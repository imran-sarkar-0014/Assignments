{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering in Python\n",
    "In the following, we will go thoguh the steps of performing k-means clustering in python. Before the model is built, we need to take care of two things in particular, if not handled before: missing values and data standardization. As we know that we calculate distances in the process, k-means is a typical example where it is really important that proper scaling is performed in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we'll use a data set which contains statistics in arrests\n",
    "# per 100,000 residents for assault, murder, and rape in each of the 50 US states in 1973.\n",
    "# It includes also the percent of the population living in urban areas.\n",
    "\n",
    "crime_rates=pd.read_csv(\"USArrests.csv\", index_col=0)\n",
    "\n",
    "crime_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see from info, there are no missing values, so this is not an issue in this case \n",
    "\n",
    "crime_rates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the \"UrbanPop\" variable is a percantage, while the other variables are frequencies per 100,000 people,\n",
    "# we need to scale/standardize the data\n",
    "\n",
    "crime_rates.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have seen standardization before, here we do it with a different function\n",
    "# After importing it, we use the apply function to change all the columns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "crime_rates_s = crime_rates.apply(lambda x: preprocessing.scale(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_rates_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can perform clustering\n",
    "# First, we try to look at the function to create the model, and try to determine the optimal k value\n",
    "# Let's look at one use of the KMeans function\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# First we create an  object with several parameters\n",
    "# n_clusters: number of clusters\n",
    "# init: cluster initialization technique, \"random\" or more advanced \"k-means++\"\n",
    "# n_init sets the number of initializations to perform. This is important because two runs can converge on \n",
    "# different cluster assignments\n",
    "# random_state: by specifying this, we make sure that we will get the same model when re-running the code\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3, init = 'k-means++', n_init = 5, random_state = 42)\n",
    "\n",
    "kmeans.fit(crime_rates_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the model, we obtain the sum of squared errors\n",
    "\n",
    "print(kmeans.inertia_)\n",
    "\n",
    "# Final locations of the centroids of clusters\n",
    "\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "# The number of iterations required to converge\n",
    "\n",
    "print(kmeans.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know how to build one model we can select the optimal k value\n",
    "# for this, we can iterate over k values, record the quality of the model for each k\n",
    "# and then visualize the performance change to use the elbow method\n",
    "# The metric to evaluate a model is sum of squared errors\n",
    "\n",
    "sse_clust = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(crime_rates_s)\n",
    "    sse_clust.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the results\n",
    "# We can confirm, that the elbow method suggets to use 4 clusters\n",
    "\n",
    "plt.plot(range(1, 11), sse_clust)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we decided on using 4 clusters, we can create the final model\n",
    "\n",
    "kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\n",
    "\n",
    "y_clust = kmeans.fit_predict(crime_rates_s)\n",
    "\n",
    "y_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to interpret the clusters. \n",
    "# As we have the cluster labels, we can simply group by that, and look at how the \n",
    "# attributes vary over clusters\n",
    "\n",
    "crime_rates.groupby(y_clust).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check what specific states are in a given cluster\n",
    "\n",
    "crime_rates[y_clust == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
